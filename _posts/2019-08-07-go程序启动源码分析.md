---
layout: post
title: 'Go程序启动源码分析'
subtitle: '从第一行源码开始阅读runtime'
date: 2019-08-07
categories: 技术
cover: ''
tags: Golang
---

测试环境：
```go
$ go version
go version go1.12.7 linux/amd64
$ uname -a
Linux wu-insparition 4.18.0-25-generic #26~18.04.1-Ubuntu SMP Thu Jun 27 07:28:31 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
```

测试范例：
```go
package main
import "fmt"
func main() {
	fmt.Println("hello,world")
}
```

程序的入口处为：

```go
// usr/local/go/src/runtime/rt0_linux_amd64.s
TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8
	JMP	_rt0_amd64(SB)
```

将断点打在`_rt0_amd64`处：

```go
TEXT _rt0_amd64(SB),NOSPLIT,$-8
	MOVQ	0(SP), DI	// argc
	LEAQ	8(SP), SI	// argv
	JMP	runtime·rt0_go(SB)
```

由于我们将断点打在用户空间的入口处，在这之前在内核中涉及到进程的`do_fork()`，这里的argc和argv应该与这个函数的参数有关，由于不影响整个流程，这里分析暂先跳过。下面执行到`rt0_go`：

```go
TEXT runtime·rt0_go(SB),NOSPLIT,$0
	MOVQ	DI, AX		// argc
	MOVQ	SI, BX		// argv
	SUBQ	$(4*8+7), SP		// 2args 2auto
	ANDQ	$~15, SP
	MOVQ	AX, 16(SP)
	MOVQ	BX, 24(SP)
```
这里做了一下参数的拷贝，栈的变化大致如下：
```
+---------+
|         |
|         |
+---------+ <--+ 0x00007fffdafd5120
|         |
|         |
+---------+ <--+ 0x00007fffdafd50f9
|         |
|         |
+---------+ <--+ 0x00007fffdafd50f0 sp
|         |
|   ...   |
|         |
+---------+
```

```go
MOVQ	$runtime·g0(SB), DI    // 这里将全局的g0放进DI
LEAQ	(-64*1024+104)(SP), BX
MOVQ	BX, g_stackguard0(DI)
MOVQ	BX, g_stackguard1(DI)  // 设置g0的stackguard0和stackguard1
MOVQ	BX, (g_stack+stack_lo)(DI)
MOVQ	SP, (g_stack+stack_hi)(DI) // 设置g0的stack.hi和stack.lo
```

可以看出g0的栈大约为64K（system stack）。省略一些读取CPU与cgo的代码，接着看：

```go
LEAQ	runtime·m0+m_tls(SB), DI // 将m0.tls的地址放进DI
CALL	runtime·settls(SB)
```
```go
TEXT runtime·settls(SB),NOSPLIT,$32
	...
	ADDQ	$8, DI	// ELF wants to use -8(FS)，这里暂时没明白为什么会这样设计TODO
	...
	MOVQ	DI, SI  // 将m0.tls的地址作为系统调用的参数之一
	MOVQ	$0x1002, DI	// ARCH_SET_FS
	MOVQ	$SYS_arch_prctl, AX // 存入系统调用号
	SYSCALL
	CMPQ	AX, $0xfffffffffffff001 // 是否成功
	JLS	2(PC) // 如果成功直接调到RET处返回
	MOVL	$0xf1, 0xf1  // crash
	RET
```

这里涉及到TLS的相关知识。总的来说做了两件事：（1）告诉kernel，用户空间以后会用FS这个段寄存器来访问TLS段（glibc使用了GS段寄存器）。（2）告诉kernel，当前线程的TSL是m0.tls。

```go
get_tls(BX)
MOVQ	$0x123, g(BX)
MOVQ	runtime·m0+m_tls(SB), AX
CMPQ	AX, $0x123
JEQ 2(PC)
CALL	runtime·abort(SB)
```
这段代码是为了测试m0的TLS是否设置成功。通过查看m0.tls[0]处的值，发现0x123确实以十进制数291的形式存入了。这里令我疑惑的是代码中的一个宏：
```c
#define g(r)    0(r)(TLS*1) 
```
从表面上，没看出这个宏的作用。通过向`get_tls(BX)`后添加一句`MOVQ	g(BX), AX`，查看rax寄存器中的值居然是0。但是不影响进行，有空再深究TODO。

```go
ok:
	// set the per-goroutine and per-mach "registers"
	get_tls(BX)
	LEAQ	runtime·g0(SB), CX  
	MOVQ	CX, g(BX) // 将g0的地址放进当前线程（m0）的TLS
	LEAQ	runtime·m0(SB), AX

	// save m->g0 = g0
	MOVQ	CX, m_g0(AX)
	// save m0 to g0->m
	MOVQ	AX, g_m(CX)

	CLD				// convention is D is always left cleared
	CALL	runtime·check(SB)
```

```go
(dlv) p m0.tls
[6]uintptr [5746784,0,0,0,0,0]
(dlv) p &g0
(*runtime.g)(0x57b060)
```
可以看到g0的地址以十进制的形式存入了m0.tls。

```go
MOVL	16(SP), AX		// copy argc
MOVL	AX, 0(SP)
MOVQ	24(SP), AX		// copy argv
MOVQ	AX, 8(SP)
```
这里拷贝参数到esp的正上方（注意中间有ret addr），这两个参数分别是下面3个初始化函数的参数：
```go
CALL	runtime·args(SB)
CALL	runtime·osinit(SB)  // 获取core个数，本机上为4
CALL	runtime·schedinit(SB)
```
```go
func schedinit() {
	// 这是一个特殊的函数，它的函数体由编译器填写
	// 这个函数的返回值有3种可能：
	// 1. m.g0
	// 2. m.gsinnal
	// 3. m.curg
	// 更多见HACKING.md
	_g_ := getg()  // 这里返回的是当前m的g0，即全局的g0
	if raceenabled {
		_g_.racectx, raceprocctx0 = raceinit()
	}

	sched.maxmcount = 10000  // 最大m数量

	tracebackinit() // skipPC=4546432
	moduledataverify() // symbol table
	stackinit()  // 初始化栈池
	mallocinit()  // 内存初始化，留着看allocator的时候再来分析TODO
	mcommoninit(_g_.m)
	cpuinit()       // must run before alginit
	alginit()       // maps must not be used before this call
	modulesinit()   // provides activeModules
	typelinksinit() // uses maps, activeModules
	itabsinit()     // uses activeModules

	msigsave(_g_.m)
	initSigmask = _g_.m.sigmask

	// 这里将g0栈上的两个fork参数拷贝到此程序的全局变量中
	goargs()
	goenvs()
	
	parsedebugvars()
	gcinit() // gc相关的初始化TODO

	sched.lastpoll = uint64(nanotime())
	procs := ncpu
	if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok && n > 0 {
		procs = n
	}
	// 初始化procs个p，并将当前m与第一个p建立联系
	if procresize(procs) != nil {
		throw("unknown runnable goroutine during bootstrap")
	}

	// For cgocheck > 1, we turn on the write barrier at all times
	// and check all pointer writes. We can't do this until after
	// procresize because the write barrier needs a P.
	if debug.cgocheck > 1 {
		writeBarrier.cgo = true
		writeBarrier.enabled = true
		for _, p := range allp {
			p.wbBuf.reset()
		}
	}

	if buildVersion == "" {
		// Condition should never trigger. This code just serves
		// to ensure runtime·buildVersion is kept in the resulting binary.
		buildVersion = "unknown"
	}
}
```

```go
// create a new goroutine to start program
MOVQ	$runtime·mainPC(SB), AX		// entry
PUSHQ	AX
PUSHQ	$0			// arg size
CALL	runtime·newproc(SB)
POPQ	AX
POPQ	AX
```
注意这里mainPC是：
```go
DATA	runtime·mainPC+0(SB)/8,$runtime·main(SB)
```

下面进入newproc函数：
```go
func newproc(siz int32, fn *funcval) {
	argp := add(unsafe.Pointer(&fn), sys.PtrSize) // argp指向第一个参数，下面做了一个小验证
	// 前面讲过，这里从当前线程的tls中取得当前正在运行的g
	// 有3中可能，这里是gp=g0
	gp := getg()  // 获得当前的g
	// getcallerpc returns the program counter (PC) of its caller's caller. 见stubs.go
	// 参考后面的一个小验证范例
	pc := getcallerpc()
	systemstack(func() {
		newproc1(fn, (*uint8)(argp), siz, gp, pc)
	})
}
```
验证代码：
```go
package main
import "fmt"
import "time"
func main() {
	i := 69
	j := 100
	go func(arg1, arg2 int){
		fmt.Println(arg1+arg2)
	}(i, j)
	time.Sleep(1*time.Second)
}
```
这里将程序build后，使用`objdump -d`查看`main()`和`newproc()`的汇编代码，画出函数的栈帧大致如下：
```
        newproc              main
      +--------+           +--------+
      |  rbp   |           |  ...   |
      +--------+           +--------+ <-+
      |  ret   |           |  rbp   |
      +--------+           +--------+ +-+
      |  TLS   |           |  69    |   |
      +--------+           +--------+   | local var
      |  16    |           |  100   |   |
      +--------+           +--------+ +-+
argp  |   |----------+     |  100   |   |
      +--------|     |     +--------+   | argument
      |   |-------+  +---> |  69    |   |
      +--------+  |        +--------+ +-+
      |  func1 |  +------> |  fun_  |
      +--------+           +--------+
      |  func1 |           |  16    |
      +--------+ <-+RSP    +--------+
                           |  ret   |
                           +--------+
```
通过栈帧结构也能看出，在newproc的栈帧中，argp指向了main函数中第一个参数的位置。值得注意的是，newproc中拷贝了上一个栈帧的ret addr到自己的本地变量中，这正是执行`pc := getcallerpc()`的效果（caller's caller）。

验证完这句代码，接下来来到`systemstack`：
```go
// func systemstack(fn func())
TEXT runtime·systemstack(SB), NOSPLIT, $0-8
	// mov    0x8(%rsp),%rdi 结合上面的栈帧结构可以知道，这里的fn指的是传进来的匿名函数
	MOVQ	fn+0(FP), DI	// DI = fn
	get_tls(CX)
	MOVQ	g(CX), AX	// AX = g  mov %fs:0xfffffffffffffff8,%rax
	MOVQ	g_m(AX), BX	// BX = m

	CMPQ	AX, m_gsignal(BX) // 判断当前执行的g是否是gsignal
	JEQ	noswitch

	MOVQ	m_g0(BX), DX	// DX = g0
	CMPQ	AX, DX   // 判断当前执行的g是否是g0，成立，跳转到noswitch，
	JEQ	noswitch
	...
noswitch:
	MOVQ	DI, DX
	MOVQ	0(DI), DI
	// 跳转到匿名函数
	// 调到注意这里使用的是JMP指令，而不是CALL指令
	// 二者的区别在于前者不会压入ret addr，后者会
	JMP	DI  
```

```go
// 这里再回忆一下这5个参数的作用：
// fn: 从asm_amd64.s中传入，为proc.go中的main函数
// argp: 参数指针，这里没有参数
// narg: 参数总大小，这里为0
// callerpg: 有3种可能，这里是g0
// callerpc: 在asm_amd64.s中执行newproc的前一条指令的地址
// 下面的分析中，只摘取了主线内容
func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) {
	_g_ := getg()  // go
	...
	// 这里与内核中禁止抢占的方式有点类似，有待考究TODO
	_g_.m.locks++ // disable preemption because it can be holding p in a local var
	...
	_p_ := _g_.m.p.ptr() // 拿到当前m的p（id为0），它们的关系在前面的procresize()函数中已经建立
	newg := gfget(_p_) // 因为目前只有一个g0，这里newg为空
	if newg == nil {
		newg = malg(_StackMin)
		casgstatus(newg, _Gidle, _Gdead)
		allgadd(newg) // publishes with a g->status of Gdead so GC scanner doesn't look at uninitialized stack.
	}
```
```go
func malg(stacksize int32) *g {
	newg := new(g)  // 分配一个g，new会进入runtime调用newObject()
	if stacksize >= 0 {
		stacksize = round2(_StackSystem + stacksize) // 2048
		systemstack(func() { // 依然是切换到g0的栈上操作
			newg.stack = stackalloc(uint32(stacksize))
		})
		newg.stackguard0 = newg.stack.lo + _StackGuard
		newg.stackguard1 = ^uintptr(0)
	}
	return newg
}
```
下面在g0栈上执行stackalloc()函数：
```go
// stackalloc allocates an n byte stack.
//
// stackalloc must run on the system stack because it uses per-P
// resources and must not split the stack.
//
//go:systemstack
//同上，此函数只摘取主线内容分析
func stackalloc(n uint32) stack {
	// Stackalloc must be called on scheduler stack, so that we
	// never try to grow the stack during the code that stackalloc runs.
	// Doing so would cause a deadlock (issue 1547).
	// 上面注释也说了，为了避免grow stack，选择在g0的栈上进行函数调用
	// 在asm_amd64.s中也提到过，g0的栈大约是64KB，是完全够用的
	thisg := getg()
	if thisg != thisg.m.g0 {
		// 在runtime中，g0的栈有两个别名，system stack和scheduler stack
		throw("stackalloc not on scheduler stack")
	}
	...
	// Small stacks are allocated with a fixed-size free-list allocator.
	// If we need a stack of a bigger size, we fall back on allocating
	// a dedicated span.
	var v unsafe.Pointer
	if n < _FixedStack<<_NumStackOrders && n < _StackCacheSize {
		order := uint8(0)
		n2 := n
		for n2 > _FixedStack { // n2=_FixedStack，略过循环
			order++
			n2 >>= 1
		}
		var x gclinkptr
		c := thisg.m.mcache
		if stackNoCache != 0 || c == nil || thisg.m.preemptoff != "" {
			// c == nil can happen in the guts of exitsyscall or
			// procresize. Just get a stack from the global pool.
			// Also don't touch stackcache during gc
			// as it's flushed concurrently.
			lock(&stackpoolmu)
			x = stackpoolalloc(order)
			unlock(&stackpoolmu)
		} else {
			x = c.stackcache[order].list
			if x.ptr() == nil {
				stackcacherefill(c, order)
				x = c.stackcache[order].list
			}
			c.stackcache[order].list = x.ptr().next
			c.stackcache[order].size -= uintptr(n)
		}
		v = unsafe.Pointer(x)
	} else {
		var s *mspan
		npage := uintptr(n) >> _PageShift
		log2npage := stacklog2(npage)

		// Try to get a stack from the large stack cache.
		lock(&stackLarge.lock)
		if !stackLarge.free[log2npage].isEmpty() {
			s = stackLarge.free[log2npage].first
			stackLarge.free[log2npage].remove(s)
		}
		unlock(&stackLarge.lock)

		if s == nil {
			// Allocate a new stack from the heap.
			s = mheap_.allocManual(npage, &memstats.stacks_inuse)
			if s == nil {
				throw("out of memory")
			}
			osStackAlloc(s)
			s.elemsize = uintptr(n)
		}
		v = unsafe.Pointer(s.base())
	}

	if raceenabled {
		racemalloc(v, uintptr(n))
	}
	if msanenabled {
		msanmalloc(v, uintptr(n))
	}
	if stackDebug >= 1 {
		print("  allocated ", v, "\n")
	}
	return stack{uintptr(v), uintptr(v) + uintptr(n)}
}
```


```
	if newg.stack.hi == 0 {
		throw("newproc1: newg missing stack")
	}

	if readgstatus(newg) != _Gdead {
		throw("newproc1: new g is not Gdead")
	}

	totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame
	totalSize += -totalSize & (sys.SpAlign - 1)                  // align to spAlign
	sp := newg.stack.hi - totalSize
	spArg := sp
	if usesLR {
		// caller's LR
		*(*uintptr)(unsafe.Pointer(sp)) = 0
		prepGoExitFrame(sp)
		spArg += sys.MinFrameSize
	}
	if narg > 0 {
		memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg))
		// This is a stack-to-stack copy. If write barriers
		// are enabled and the source stack is grey (the
		// destination is always black), then perform a
		// barrier copy. We do this *after* the memmove
		// because the destination stack may have garbage on
		// it.
		if writeBarrier.needed && !_g_.m.curg.gcscandone {
			f := findfunc(fn.fn)
			stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps))
			if stkmap.nbit > 0 {
				// We're in the prologue, so it's always stack map index 0.
				bv := stackmapdata(stkmap, 0)
				bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata)
			}
		}
	}

	memclrNoHeapPointers(unsafe.Pointer(&newg.sched), unsafe.Sizeof(newg.sched))
	newg.sched.sp = sp
	newg.stktopsp = sp
	newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
	newg.sched.g = guintptr(unsafe.Pointer(newg))
	gostartcallfn(&newg.sched, fn)
	newg.gopc = callerpc
	newg.ancestors = saveAncestors(callergp)
	newg.startpc = fn.fn
	if _g_.m.curg != nil {
		newg.labels = _g_.m.curg.labels
	}
	if isSystemGoroutine(newg, false) {
		atomic.Xadd(&sched.ngsys, +1)
	}
	newg.gcscanvalid = false
	casgstatus(newg, _Gdead, _Grunnable)

	if _p_.goidcache == _p_.goidcacheend {
		// Sched.goidgen is the last allocated id,
		// this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch].
		// At startup sched.goidgen=0, so main goroutine receives goid=1.
		_p_.goidcache = atomic.Xadd64(&sched.goidgen, _GoidCacheBatch)
		_p_.goidcache -= _GoidCacheBatch - 1
		_p_.goidcacheend = _p_.goidcache + _GoidCacheBatch
	}
	newg.goid = int64(_p_.goidcache)
	_p_.goidcache++
	if raceenabled {
		newg.racectx = racegostart(callerpc)
	}
	if trace.enabled {
		traceGoCreate(newg, newg.startpc)
	}
	runqput(_p_, newg, true)

	if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 && mainStarted {
		wakep()
	}
	_g_.m.locks--
	if _g_.m.locks == 0 && _g_.preempt { // restore the preemption request in case we've cleared it in newstack
		_g_.stackguard0 = stackPreempt
	}
}
```


```go
// start this M
CALL	runtime·mstart(SB)

CALL	runtime·abort(SB)	// mstart should never return
RET

// Prevent dead-code elimination of debugCallV1, which is
// intended to be called by debuggers.
MOVQ	$runtime·debugCallV1(SB), AX
RET
```




